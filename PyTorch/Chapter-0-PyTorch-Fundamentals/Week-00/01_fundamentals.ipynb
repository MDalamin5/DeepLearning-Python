{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "302c2489-54d9-46ea-8b20-826ca5c73e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4fd031-b3f3-411d-81d0-ef4911903235",
   "metadata": {},
   "source": [
    "## Reshaping, stacking, squeezing and unsqueezing tensors\n",
    "\n",
    "* Reshaping - reshapes an input tensor to a defined shape\n",
    "* View - Return a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
    "* Stacking - combine multiple tensor on top of each other (vstack) or side by side (hstack)\n",
    "* Squeeze - removes all `1` dimensions from a tensor\n",
    "* Unsqueeze - add a `1` dimension to a target tensor\n",
    "* Permute - Return a view of the input with dimensions permuted (swapped) in a certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c031834c-8bd8-4611-bfff-ff1d927f3dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]), 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a tensor\n",
    "x = torch.arange(1., 10.)\n",
    "x, x.shape, x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57ffe3f0-bde3-417c-9dcb-a3f0609a33f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]), 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an extra dimension\n",
    "\n",
    "x_reshaped = x.reshape(1, 9)\n",
    "x_reshaped, x_reshaped.shape, x_reshaped.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "483bf38a-2b53-4b5f-b1b3-7ce8a9362ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [7.],\n",
       "         [8.],\n",
       "         [9.]]),\n",
       " torch.Size([9, 1]),\n",
       " 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rereshape = x.reshape(9, 1)\n",
    "x_rereshape, x_rereshape.shape, x_rereshape.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c0084af-a99d-4962-af7e-c5b671378ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.]),\n",
       " torch.Size([12]),\n",
       " 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_again = torch.arange(1., 13,)\n",
    "x_again, x_again.shape, x_again.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "458e1a2c-785d-44d9-bba3-a21e995b8d23",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[2, 5]' is invalid for input of size 12",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mx_again\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[2, 5]' is invalid for input of size 12"
     ]
    }
   ],
   "source": [
    "x_again.reshape(2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45bce27c-593f-4944-9b68-811f67c79e56",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[5, 2]' is invalid for input of size 12",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mx_again\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[5, 2]' is invalid for input of size 12"
     ]
    }
   ],
   "source": [
    "x_again.reshape(5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebb02fa0-8282-410d-afe0-c2f2f43ffe02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.],\n",
       "        [ 5.,  6.,  7.,  8.],\n",
       "        [ 9., 10., 11., 12.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_again.reshape(3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a4ad9c-f0e4-4082-b539-58a286998f9e",
   "metadata": {},
   "source": [
    "# Change the view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64db94cc-b28b-4707-9243-f2cd5c0c31a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x.view(1, 9)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca6b247c-2584-4e8f-8c5a-1b761e969ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " tensor([4., 2., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing z changes x (because a view of a tensor shares the same memore as the original input)\n",
    "\n",
    "z[:, 0] = 4\n",
    "z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22ff993e-a276-447b-8665-9d377449b0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [4., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [4., 2., 3., 4., 5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stack tensors on top of each other\n",
    "x_stacked = torch.stack([x, x, x], dim=0)\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b3cc771-1235-43fd-bbc2-ad1fa73c15ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 4., 4.],\n",
       "        [2., 2., 2.],\n",
       "        [3., 3., 3.],\n",
       "        [4., 4., 4.],\n",
       "        [5., 5., 5.],\n",
       "        [6., 6., 6.],\n",
       "        [7., 7., 7.],\n",
       "        [8., 8., 8.],\n",
       "        [9., 9., 9.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stacked = torch.stack([x, x, x], dim=1)\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6726e1-b7d2-453f-8872-c24cddf6b035",
   "metadata": {},
   "source": [
    "# Squeezing, Unsqueezing and permutin tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b90ffbc-cf9d-4fe6-8f6d-4b31922806aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 2., 3., 4., 5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3722fe72-23ab-46d2-9adc-1d0c72c56d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[4., 2., 3., 4., 5., 6., 7., 8., 9.]]) \n",
      "Previous shape: torch.Size([1, 9]) \n",
      "\n",
      "NEW tensor: tensor([4., 2., 3., 4., 5., 6., 7., 8., 9.]) \n",
      "NEW shape: torch.Size([9]) \n"
     ]
    }
   ],
   "source": [
    "# torch.squeeze() removes all single dimensions from the target tensor\n",
    "\n",
    "print(f\"Previous tensor: {x_reshaped} \")\n",
    "print(f\"Previous shape: {x_reshaped.shape} \")\n",
    "\n",
    "# Remove extra dimensions from x reshaped\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "print(f\"\\nNEW tensor: {x_squeezed} \")\n",
    "print(f\"NEW shape: {x_squeezed.shape} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9853f1c8-abae-43d7-9d10-fa7c95245f69",
   "metadata": {},
   "source": [
    "# torch.unsqueeze() -adds a single dimnension to a target tensor at a specific dim (dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b369a2b3-adb8-4db2-9233-aed49204a4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previors target: tensor([4., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "Previors shaperd: torch.Size([9])\n",
      "\n",
      "\n",
      "NEw Tensor: tensor([[4., 2., 3., 4., 5., 6., 7., 8., 9.]]) \n",
      "NEw Tensor shaped: torch.Size([1, 9]) \n"
     ]
    }
   ],
   "source": [
    "print(f\"Previors target: {x_squeezed}\")\n",
    "print(f\"Previors shaperd: {x_squeezed.shape}\")\n",
    "print()\n",
    "\n",
    "# add an extra dim with unsqueeze\n",
    "\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
    "print(f\"\\nNEw Tensor: {x_unsqueezed} \")\n",
    "print(f\"NEw Tensor shaped: {x_unsqueezed.shape} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0015a8ad-8a06-4125-ba19-eafc8099f77d",
   "metadata": {},
   "source": [
    "# torch.permute - rearragnges the dim of a target tensor in a specified order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58b02c04-6a13-4ca3-a85b-91939f6b39fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: torch.Size([224, 224, 3]) \n",
      "New shape: torch.Size([3, 224, 224]) \n"
     ]
    }
   ],
   "source": [
    "x_original = torch.rand(224, 224, 3) # [height, width, color channel-RGB]\n",
    "\n",
    "# Permute the original tensor to rearragne the axis(or dim) order\n",
    "x_permuted = x_original.permute(2, 0, 1) # shigts 0->1, 1->2, 2->0\n",
    "\n",
    "print(f\"Previous shape: {x_original.shape} \")\n",
    "print(f\"New shape: {x_permuted.shape} \")\n",
    "\n",
    "# permute work as a view like its share the memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b456f7b6-7e63-470b-a8bf-b980a58d9e55",
   "metadata": {},
   "source": [
    "## Selecting data form tensor(indexing)\n",
    "indexing with PyTorch to indexing with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8583335c-af77-40c3-8f7c-5be3b0215f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(9.), tensor(9.))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_original[0, 0, 0] = 9\n",
    "x_original[0, 0, 0], x_permuted[0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfa84f10-fe79-4ff0-a5db-d5e1728c5404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating tensor\n",
    "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec2e0504-9c2f-4366-9226-5d9ec62f7019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's index on our new tensor\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c51fc13c-69c6-4983-a5f1-ea5e82e053e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0072b762-4784-4ccd-945c-847d169b2c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5, 6])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26e70f50-42fb-420f-9202-a62380138da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12c82efb-2c30-4db3-b79b-6a76e4980d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# access number 9\n",
    "x[0, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3fc1405f-bd60-429d-be6d-64542aec18be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48095f60-5093-43e2-b9f2-9422496ddc4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get index o of 0th 1st dim and all values of 2nd dim\n",
    "\n",
    "x[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7d046ee-79d5-419c-bc65-4742dba98a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 6, 9]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca5e6ec-0b81-4931-996a-ea6df6e3c375",
   "metadata": {},
   "source": [
    "## PyTorch tensors & NumPy\n",
    "Numpy is popular scientific Python numerical computing library.\n",
    "\n",
    "* Data in Numpy, want in pythorch tensor --> `torch.from_numpy(ndarray)`\n",
    "* PyTorch tensor -> NUMPY --> `torch.Tensor.numpy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7549a677-9d84-456e-bb11-52e12f990859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy array to tensor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ea9cdb0-d0cb-434e-a713-7ce61b35ba33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.arange(1., 8.)\n",
    "tensor = torch.from_numpy(array)\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c60476ac-1bb5-45ab-9abd-8b083298d676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6a885e4c-97e6-41e0-8928-f8391b85f3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 7.,  8.,  9., 10., 11., 12., 13.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the value of array\n",
    "array = array + 2\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c29cfbb5-135b-4f12-8334-a857eada98ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.ones(7)\n",
    "numpy_tensor = tensor.numpy()\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bc08ae42-73c0-4800-b5b7-e76f8d2e5a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efa73ec-4dda-4097-8386-7fb5d6a748c6",
   "metadata": {},
   "source": [
    "# Change the tensor, to see what happens to `numpy_tensor`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1063c297-4389-4c01-a8bd-76d703566a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tensor + 1\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "217f8f54-ceb4-4b0f-9df5-728ce7cc643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51286fbb-1c98-4437-881f-9181d26a31cf",
   "metadata": {},
   "source": [
    "## Reproducbility (trying to take random out of random)\n",
    "\n",
    "To reduce the randomness in neural networks and PyTorch comes the oncept of a **random seed**.\n",
    "Essentially what the random seed does is \"flavour the randomness.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "015fc63b-aad7-427d-84c1-5bbbf14a079e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1121, 0.1398, 0.1166, 0.9165],\n",
      "        [0.8303, 0.0171, 0.4239, 0.7844],\n",
      "        [0.8946, 0.9953, 0.2092, 0.0111]])\n",
      "tensor([[0.8130, 0.1184, 0.8583, 0.8153],\n",
      "        [0.8312, 0.2527, 0.9039, 0.8214],\n",
      "        [0.7341, 0.7908, 0.5836, 0.8447]])\n",
      "\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "random_tensor_a = torch.rand(3, 4)\n",
    "random_tensor_b = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_a)\n",
    "print(random_tensor_b)\n",
    "print()\n",
    "print(random_tensor_a == random_tensor_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "621b1b07-772b-4ffc-8622-a96ce99db62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "# leats make some random but reproducible tensors\n",
    "\n",
    "# Set the random seed\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "random_tensor_c = torch.rand(3, 4)\n",
    "print(random_tensor_c)\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "random_tensor_d = torch.rand(3, 4)\n",
    "print(random_tensor_d)\n",
    "print()\n",
    "print(random_tensor_c == random_tensor_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce08a272-50fb-46e8-bd41-62cf3996c1e3",
   "metadata": {},
   "source": [
    "## Getting a GPU\n",
    "\n",
    "https://timdettmers.com/category/deep-learning/\n",
    "\n",
    "cloud computin -GCP, AWS, Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22bca46f-f670-43b4-b63e-4ff497eb0db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1534c97d-08bb-4b40-875c-c7f9c0e9e2c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24ea3840-e2aa-4e74-b4ba-1e1ee9b03227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebd905e-4572-42a1-8ed7-b001299cb86d",
   "metadata": {},
   "source": [
    "doc: https://pytorch.org/docs/stable/notes/cuda.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d0e6e7-183d-4689-bb5a-2dbeec451540",
   "metadata": {},
   "source": [
    "## Putting tensors (and models) on the GPU\n",
    "\n",
    "the reson we want out tensors/models on the gpu is because using a GPU results in faster computeations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "835a6677-b25e-42d7-a869-ab37f6f9d016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    }
   ],
   "source": [
    "# create a tensor (Defafult on the CPU)\n",
    "\n",
    "tensor = torch.tensor([1,2 ,3],)\n",
    "\n",
    "# tensor not on GPU\n",
    "print(tensor, tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c15b4de5-ef2e-4159-92c8-107f5b4039d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# move tensor to GPU(if available)\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384f26a5-1878-4858-b2b9-67153d0b413d",
   "metadata": {},
   "source": [
    "# Moving tensor back to the cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05e3897b-a82c-4f7d-be9e-5770b1e31646",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# if tensor is on GPU, can't transform it to NumPy\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtensor_on_gpu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "# if tensor is on GPU, can't transform it to NumPy\n",
    "tensor_on_gpu.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46411def-f1a5-4a5c-9bd2-4d78f96eb2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to fix the gpu tensor with Numpy issues we can first set it oto the CPU\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb40a76-f809-435f-a404-1e6f2bdec2bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
